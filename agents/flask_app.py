#!/usr/bin/env python3
"""
Complete Production-Ready Flask Backend for Resume Analyzer
Features: Rate limiting, caching, logging, database, error handling
"""

from flask import Flask, request, jsonify, render_template_string, send_from_directory
from flask_cors import CORS
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from flask_caching import Cache
import os
import tempfile
from werkzeug.utils import secure_filename
import json
import logging
from pathlib import Path
import datetime
import sqlite3
import hashlib
import time
import traceback
from typing import Dict, Any, Optional

# Import your existing analyzer
try:
    from resume_analyzer_enhanced import ResumeAnalyzer
except ImportError:
    print("‚ùå Could not import ResumeAnalyzer. Make sure resume_analyzer_enhanced.py is in the same directory.")
    print("   You can still run the server, but analysis will not work.")
    ResumeAnalyzer = None

# Setup Flask app with production configurations
app = Flask(__name__)
app.config.update(
    MAX_CONTENT_LENGTH=16 * 1024 * 1024,  # 16MB max file size
    UPLOAD_FOLDER=tempfile.gettempdir(),
    SECRET_KEY=os.getenv('SECRET_KEY', 'dev-key-change-in-production'),
    
    # Database configuration
    DATABASE_URL=os.getenv('DATABASE_URL', 'sqlite:///resume_analyzer.db'),
    
    # Cache configuration
    CACHE_TYPE=os.getenv('CACHE_TYPE', 'simple'),
    CACHE_DEFAULT_TIMEOUT=300,  # 5 minutes
    
    # Rate limiting
    RATELIMIT_STORAGE_URL=os.getenv('REDIS_URL', 'memory://'),
    
    # Environment
    ENV=os.getenv('FLASK_ENV', 'production'),
    DEBUG=os.getenv('FLASK_ENV') == 'development'
)

# Setup extensions
CORS(app)
cache = Cache(app)
limiter = Limiter(
    key_func=get_remote_address,
    default_limits=["200 per day", "50 per hour"]
)
limiter.init_app(app)

# Setup comprehensive logging
if not app.debug:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s %(levelname)s %(name)s %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('app.log')
        ]
    )
else:
    logging.basicConfig(level=logging.DEBUG)

logger = logging.getLogger(__name__)

# Database setup
def init_db():
    """Initialize database with required tables"""
    try:
        conn = sqlite3.connect('resume_analyzer.db')
        cursor = conn.cursor()
        
        # Analytics table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analytics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                ip_address TEXT,
                user_agent TEXT,
                analysis_type TEXT,
                processing_time REAL,
                success BOOLEAN,
                error_message TEXT,
                resume_length INTEGER,
                file_size INTEGER
            )
        ''')
        
        # Cache table for expensive operations
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analysis_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content_hash TEXT UNIQUE,
                analysis_result TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                accessed_count INTEGER DEFAULT 0,
                last_accessed DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # User feedback table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS feedback (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                ip_address TEXT,
                rating INTEGER,
                comments TEXT,
                analysis_id TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("Database initialized successfully")
        
    except Exception as e:
        logger.error(f"Database initialization error: {e}")

# Initialize database on startup
init_db()

# Utility functions
def log_analytics(ip_address: str, user_agent: str, analysis_type: str, 
                 processing_time: float, success: bool, error_message: str = None,
                 resume_length: int = None, file_size: int = None):
    """Log analytics data"""
    try:
        conn = sqlite3.connect('resume_analyzer.db')
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO analytics 
            (ip_address, user_agent, analysis_type, processing_time, success, 
             error_message, resume_length, file_size)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (ip_address, user_agent, analysis_type, processing_time, success, 
              error_message, resume_length, file_size))
        conn.commit()
        conn.close()
    except Exception as e:
        logger.error(f"Analytics logging error: {e}")

def get_content_hash(content: str) -> str:
    """Generate hash for content caching"""
    return hashlib.sha256(content.encode()).hexdigest()

def cache_analysis(content_hash: str, analysis_result: Dict[str, Any]):
    """Cache analysis result"""
    try:
        conn = sqlite3.connect('resume_analyzer.db')
        cursor = conn.cursor()
        cursor.execute('''
            INSERT OR REPLACE INTO analysis_cache 
            (content_hash, analysis_result, created_at, accessed_count, last_accessed)
            VALUES (?, ?, CURRENT_TIMESTAMP, 
                    COALESCE((SELECT accessed_count FROM analysis_cache WHERE content_hash = ?), 0) + 1,
                    CURRENT_TIMESTAMP)
        ''', (content_hash, json.dumps(analysis_result), content_hash))
        conn.commit()
        conn.close()
    except Exception as e:
        logger.error(f"Cache storage error: {e}")

def get_cached_analysis(content_hash: str) -> Optional[Dict[str, Any]]:
    """Retrieve cached analysis result"""
    try:
        conn = sqlite3.connect('resume_analyzer.db')
        cursor = conn.cursor()
        cursor.execute('''
            SELECT analysis_result FROM analysis_cache 
            WHERE content_hash = ? AND 
                  datetime(created_at) > datetime('now', '-24 hours')
        ''', (content_hash,))
        result = cursor.fetchone()
        
        if result:
            # Update access stats
            cursor.execute('''
                UPDATE analysis_cache 
                SET accessed_count = accessed_count + 1,
                    last_accessed = CURRENT_TIMESTAMP
                WHERE content_hash = ?
            ''', (content_hash,))
            conn.commit()
            conn.close()
            return json.loads(result[0])
            
        conn.close()
        return None
    except Exception as e:
        logger.error(f"Cache retrieval error: {e}")
        return None

def validate_resume_content(content: str) -> tuple[bool, str]:
    """Validate resume content"""
    if not content or len(content.strip()) < 50:
        return False, "Resume content too short (minimum 50 characters required)"
    
    if len(content) > 50000:  # 50KB text limit
        return False, "Resume content too long (maximum 50,000 characters allowed)"
    
    # Basic content validation
    content_lower = content.lower()
    has_experience_markers = any(keyword in content_lower for keyword in 
                               ['experience', 'work', 'employment', 'job', 'position', 'role'])
    has_skills_markers = any(keyword in content_lower for keyword in 
                           ['skills', 'abilities', 'competencies', 'technologies'])
    
    if not (has_experience_markers or has_skills_markers):
        return False, "Content doesn't appear to be a resume (missing experience or skills sections)"
    
    return True, "Valid"

# Error handlers
@app.errorhandler(413)
def too_large(e):
    """Handle file too large error"""
    return jsonify({
        'success': False,
        'error': 'File too large. Maximum size is 16MB.',
        'code': 'FILE_TOO_LARGE'
    }), 413

@app.errorhandler(429)
def ratelimit_handler(e):
    """Handle rate limit exceeded"""
    return jsonify({
        'success': False,
        'error': 'Rate limit exceeded. Please try again later.',
        'code': 'RATE_LIMIT_EXCEEDED',
        'retry_after': str(e.retry_after) if hasattr(e, 'retry_after') else None
    }), 429

@app.errorhandler(404)
def not_found(e):
    """Handle 404 errors"""
    return jsonify({
        'success': False,
        'error': 'Endpoint not found',
        'code': 'NOT_FOUND'
    }), 404

@app.errorhandler(500)
def internal_error(e):
    """Handle internal server errors"""
    logger.error(f"Internal server error: {e}")
    return jsonify({
        'success': False,
        'error': 'Internal server error',
        'code': 'INTERNAL_ERROR'
    }), 500

# Routes
@app.route('/')
def index():
    """Serve the main HTML interface"""
    # Load the complete HTML from the previous artifact
    html_content = r"""
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>AI Resume Analyzer - Get Instant Job Recommendations</title>
        <style>
            * {
                margin: 0;
                padding: 0;
                box-sizing: border-box;
            }

            body {
                font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                color: #333;
            }

            .container {
                max-width: 1200px;
                margin: 0 auto;
                padding: 2rem;
            }

            .hero {
                text-align: center;
                margin-bottom: 3rem;
                color: white;
            }

            .hero h1 {
                font-size: 3rem;
                margin-bottom: 1rem;
                font-weight: 700;
                text-shadow: 0 2px 4px rgba(0,0,0,0.3);
            }

            .hero p {
                font-size: 1.2rem;
                opacity: 0.9;
                margin-bottom: 2rem;
            }

            .features {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 1rem;
                margin-bottom: 2rem;
            }

            .feature {
                background: rgba(255,255,255,0.1);
                backdrop-filter: blur(10px);
                border: 1px solid rgba(255,255,255,0.2);
                border-radius: 12px;
                padding: 1.5rem;
                text-align: center;
                color: white;
            }

            .feature-icon {
                font-size: 2.5rem;
                margin-bottom: 1rem;
            }

            .analyzer-card {
                background: white;
                border-radius: 20px;
                box-shadow: 0 20px 40px rgba(0,0,0,0.1);
                overflow: hidden;
                margin-top: 2rem;
            }

            .card-header {
                background: linear-gradient(135deg, #4CAF50, #45a049);
                color: white;
                padding: 2rem;
                text-align: center;
            }

            .card-header h2 {
                font-size: 1.8rem;
                margin-bottom: 0.5rem;
            }

            .card-content {
                padding: 2rem;
            }

            .upload-section {
                border: 3px dashed #ddd;
                border-radius: 12px;
                padding: 3rem 2rem;
                text-align: center;
                margin-bottom: 2rem;
                transition: all 0.3s ease;
                cursor: pointer;
            }

            .upload-section:hover {
                border-color: #4CAF50;
                background: #f9f9f9;
            }

            .upload-section.dragover {
                border-color: #4CAF50;
                background: #e8f5e8;
            }

            .upload-icon {
                font-size: 3rem;
                color: #4CAF50;
                margin-bottom: 1rem;
            }

            .file-input {
                display: none;
            }

            .upload-btn {
                background: #4CAF50;
                color: white;
                border: none;
                padding: 1rem 2rem;
                border-radius: 8px;
                font-size: 1.1rem;
                cursor: pointer;
                transition: background 0.3s ease;
                margin-top: 1rem;
            }

            .upload-btn:hover {
                background: #45a049;
            }

            .text-section {
                margin-top: 2rem;
            }

            .text-area {
                width: 100%;
                min-height: 200px;
                border: 2px solid #ddd;
                border-radius: 8px;
                padding: 1rem;
                font-size: 1rem;
                font-family: 'Courier New', monospace;
                resize: vertical;
            }

            .text-area:focus {
                outline: none;
                border-color: #4CAF50;
            }

            .analyze-btn {
                background: linear-gradient(135deg, #FF6B6B, #FF5252);
                color: white;
                border: none;
                padding: 1.2rem 3rem;
                border-radius: 50px;
                font-size: 1.2rem;
                font-weight: 600;
                cursor: pointer;
                transition: all 0.3s ease;
                width: 100%;
                margin-top: 1.5rem;
                position: relative;
                overflow: hidden;
            }

            .analyze-btn:hover {
                transform: translateY(-2px);
                box-shadow: 0 10px 20px rgba(255,107,107,0.3);
            }

            .analyze-btn:disabled {
                background: #ccc;
                cursor: not-allowed;
                transform: none;
                box-shadow: none;
            }

            .loading {
                display: none;
                text-align: center;
                padding: 2rem;
            }

            .spinner {
                width: 50px;
                height: 50px;
                border: 4px solid #f3f3f3;
                border-top: 4px solid #4CAF50;
                border-radius: 50%;
                animation: spin 1s linear infinite;
                margin: 0 auto 1rem;
            }

            @keyframes spin {
                0% { transform: rotate(0deg); }
                100% { transform: rotate(360deg); }
            }

            .results-section {
                display: none;
                margin-top: 2rem;
                background: #f8f9fa;
                border-radius: 12px;
                padding: 2rem;
            }

            .profile-summary {
                background: white;
                border-radius: 8px;
                padding: 1.5rem;
                margin-bottom: 2rem;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }

            .profile-grid {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 1rem;
                margin-top: 1rem;
            }

            .profile-item {
                background: #f8f9fa;
                padding: 1rem;
                border-radius: 6px;
                border-left: 4px solid #4CAF50;
            }

            .profile-item strong {
                color: #333;
                display: block;
                margin-bottom: 0.5rem;
            }

            .analysis-content {
                background: white;
                border-radius: 8px;
                padding: 2rem;
                line-height: 1.6;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }

            .error-message {
                background: #fee;
                border: 1px solid #fcc;
                color: #c33;
                padding: 1rem;
                border-radius: 8px;
                margin-top: 1rem;
                display: none;
            }

            .success-message {
                background: #efe;
                border: 1px solid #cfc;
                color: #3c3;
                padding: 1rem;
                border-radius: 8px;
                margin-top: 1rem;
                display: none;
            }

            .feedback-section {
                background: white;
                border-radius: 8px;
                padding: 1.5rem;
                margin-top: 2rem;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }

            .rating-stars {
                display: flex;
                gap: 0.5rem;
                margin: 1rem 0;
            }

            .star {
                font-size: 1.5rem;
                color: #ddd;
                cursor: pointer;
                transition: color 0.2s;
            }

            .star:hover,
            .star.active {
                color: #FFD700;
            }

            @media (max-width: 768px) {
                .hero h1 {
                    font-size: 2rem;
                }
                
                .container {
                    padding: 1rem;
                }
                
                .card-content {
                    padding: 1rem;
                }
            }
        </style>
    </head>
    <body>
        <div class="container">
            <div class="hero">
                <h1>üéØ AI Resume Analyzer</h1>
                <p>Get instant job recommendations and market insights powered by advanced AI</p>
                
                <div class="features">
                    <div class="feature">
                        <div class="feature-icon">üß†</div>
                        <h3>AI-Powered Analysis</h3>
                        <p>Advanced AI extracts your profile and recommends perfect-fit jobs</p>
                    </div>
                    <div class="feature">
                        <div class="feature-icon">üí∞</div>
                        <h3>Real Salary Data</h3>
                        <p>Get market-accurate salary ranges based on your experience</p>
                    </div>
                    <div class="feature">
                        <div class="feature-icon">üìä</div>
                        <h3>Market Insights</h3>
                        <p>Comprehensive analysis of your competitiveness in the job market</p>
                    </div>
                </div>
            </div>

            <div class="analyzer-card">
                <div class="card-header">
                    <h2>Upload Your Resume</h2>
                    <p>PDF files or paste your resume text below</p>
                </div>
                
                <div class="card-content">
                    <div class="upload-section" onclick="document.getElementById('file-input').click()">
                        <div class="upload-icon">üìÑ</div>
                        <h3>Drop your PDF resume here</h3>
                        <p>or click to browse files</p>
                        <input type="file" id="file-input" class="file-input" accept=".pdf" />
                        <button class="upload-btn" type="button">Choose File</button>
                    </div>

                    <div class="text-section">
                        <h3 style="margin-bottom: 1rem;">Or paste your resume text:</h3>
                        <textarea id="resume-text" class="text-area" placeholder="Paste your resume text here...

Example:
John Smith
Software Engineer

EXPERIENCE
Senior Software Developer | ABC Tech | 2020-2024
‚Ä¢ Developed scalable web applications using React and Node.js
‚Ä¢ Led a team of 5 developers on multiple projects
‚Ä¢ Improved system performance by 40%

SKILLS
JavaScript, Python, React, AWS, Docker, SQL

EDUCATION
Bachelor of Science in Computer Science | XYZ University | 2018"></textarea>
                    </div>

                    <button id="analyze-btn" class="analyze-btn" onclick="analyzeResume()">
                        üöÄ Analyze My Resume
                    </button>

                    <div id="loading" class="loading">
                        <div class="spinner"></div>
                        <h3>Analyzing your resume...</h3>
                        <p>AI is extracting your profile and finding perfect job matches</p>
                    </div>

                    <div id="error-message" class="error-message"></div>
                    <div id="success-message" class="success-message"></div>

                    <div id="results" class="results-section">
                        <h2>üìä Your AI-Powered Career Analysis</h2>
                        
                        <div class="profile-summary">
                            <h3>ü§ñ AI-Extracted Profile</h3>
                            <div id="profile-content" class="profile-grid">
                                <!-- Profile items will be inserted here -->
                            </div>
                        </div>

                        <div class="analysis-content">
                            <h3>üìù Detailed Analysis & Recommendations</h3>
                            <div id="analysis-text">
                                <!-- Analysis content will be inserted here -->
                            </div>
                        </div>

                        <div class="feedback-section">
                            <h3>üìù How was this analysis?</h3>
                            <p>Your feedback helps us improve!</p>
                            <div class="rating-stars">
                                <span class="star" data-rating="1">‚≠ê</span>
                                <span class="star" data-rating="2">‚≠ê</span>
                                <span class="star" data-rating="3">‚≠ê</span>
                                <span class="star" data-rating="4">‚≠ê</span>
                                <span class="star" data-rating="5">‚≠ê</span>
                            </div>
                            <textarea id="feedback-text" placeholder="Optional: Tell us what you thought..." style="width: 100%; margin-top: 1rem; padding: 0.5rem; border: 1px solid #ddd; border-radius: 4px; resize: vertical;"></textarea>
                            <button onclick="submitFeedback()" style="margin-top: 1rem; padding: 0.5rem 1rem; background: #4CAF50; color: white; border: none; border-radius: 4px; cursor: pointer;">Submit Feedback</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <script>
            // Global variables
            let selectedFile = null;
            let currentAnalysisId = null;
            let selectedRating = 0;

            // File upload handling
            const fileInput = document.getElementById('file-input');
            const uploadSection = document.querySelector('.upload-section');

            fileInput.addEventListener('change', function(e) {
                const file = e.target.files[0];
                if (file) {
                    selectedFile = file;
                    uploadSection.innerHTML = `
                        <div class="upload-icon">‚úÖ</div>
                        <h3>${file.name}</h3>
                        <p>Ready to analyze</p>
                        <button class="upload-btn" onclick="document.getElementById('file-input').click()">Change File</button>
                    `;
                    showSuccess(`File "${file.name}" uploaded successfully!`);
                }
            });

            // Drag and drop functionality
            uploadSection.addEventListener('dragover', function(e) {
                e.preventDefault();
                uploadSection.classList.add('dragover');
            });

            uploadSection.addEventListener('dragleave', function(e) {
                e.preventDefault();
                uploadSection.classList.remove('dragover');
            });

            uploadSection.addEventListener('drop', function(e) {
                e.preventDefault();
                uploadSection.classList.remove('dragover');
                
                const files = e.dataTransfer.files;
                if (files.length > 0 && files[0].type === 'application/pdf') {
                    selectedFile = files[0];
                    fileInput.files = files;
                    uploadSection.innerHTML = `
                        <div class="upload-icon">‚úÖ</div>
                        <h3>${files[0].name}</h3>
                        <p>Ready to analyze</p>
                        <button class="upload-btn" onclick="document.getElementById('file-input').click()">Change File</button>
                    `;
                    showSuccess(`File "${files[0].name}" uploaded successfully!`);
                } else {
                    showError('Please upload a PDF file.');
                }
            });

            // Main analysis function
            async function analyzeResume() {
                const resumeText = document.getElementById('resume-text').value.trim();
                
                // Validation
                if (!selectedFile && !resumeText) {
                    showError('Please upload a PDF file or paste your resume text.');
                    return;
                }

                // Show loading state
                showLoading(true);
                hideMessages();

                try {
                    let analysisData;

                    if (selectedFile) {
                        analysisData = await analyzeWithPDF(selectedFile);
                    } else {
                        analysisData = await analyzeWithText(resumeText);
                    }

                    displayResults(analysisData);
                    showSuccess('Analysis completed successfully!');

                } catch (error) {
                    console.error('Analysis error:', error);
                    
                    // Handle specific error types
                    if (error.message.includes('Rate limit')) {
                        showError('Too many requests. Please try again in a few minutes.');
                    } else if (error.message.includes('too short')) {
                        showError('Resume content is too short. Please provide more detailed information.');
                    } else if (error.message.includes('too large')) {
                        showError('File is too large. Maximum size is 16MB.');
                    } else {
                        showError(`Analysis failed: ${error.message}`);
                    }
                } finally {
                    showLoading(false);
                }
            }

            // Real Flask backend API calls
            async function analyzeWithText(resumeText) {
                const response = await fetch('/analyze-text', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ resume_text: resumeText })
                });
                
                const data = await response.json();
                
                if (!response.ok) {
                    throw new Error(data.error || `HTTP ${response.status}`);
                }
                
                return data;
            }

            async function analyzeWithPDF(file) {
                const formData = new FormData();
                formData.append('file', file);
                
                const response = await fetch('/analyze-pdf', {
                    method: 'POST',
                    body: formData
                });
                
                const data = await response.json();
                
                if (!response.ok) {
                    throw new Error(data.error || `HTTP ${response.status}`);
                }
                
                return data;
            }

            // Display results
            function displayResults(data) {
                const resultsSection = document.getElementById('results');
                const profileContent = document.getElementById('profile-content');
                const analysisText = document.getElementById('analysis-text');

                if (data.success) {
                    const profile = data.extracted_profile;
                    currentAnalysisId = data.analysis_id || Date.now().toString();
                    
                    // Display profile
                    profileContent.innerHTML = `
                        <div class="profile-item">
                            <strong>Experience Level</strong>
                            ${profile.experience_level ? profile.experience_level.charAt(0).toUpperCase() + profile.experience_level.slice(1) : 'N/A'}
                        </div>
                        <div class="profile-item">
                            <strong>Years of Experience</strong>
                            ${profile.years_of_experience || 'N/A'}
                        </div>
                        <div class="profile-item">
                            <strong>Target Roles</strong>
                            ${profile.target_roles ? profile.target_roles.join(', ') : 'N/A'}
                        </div>
                        <div class="profile-item">
                            <strong>Key Skills</strong>
                            ${profile.key_skills ? profile.key_skills.join(', ') : 'N/A'}
                        </div>
                        <div class="profile-item">
                            <strong>Estimated Salary</strong>
                            ${profile.estimated_salary_range || 'N/A'}
                        </div>
                        <div class="profile-item">
                            <strong>Work Preference</strong>
                            ${profile.work_arrangement_preference || 'N/A'}
                        </div>
                    `;

                    // Display analysis
                    if (data.groq_analysis && data.groq_analysis.success) {
                        const formattedAnalysis = formatAnalysisText(data.groq_analysis.analysis);
                        analysisText.innerHTML = formattedAnalysis;
                    } else {
                        analysisText.innerHTML = '<p>Analysis not available. Please try again.</p>';
                    }

                    resultsSection.style.display = 'block';
                    resultsSection.scrollIntoView({ behavior: 'smooth' });
                } else {
                    throw new Error(data.error || 'Analysis failed');
                }
            }

            // Feedback functionality
            document.querySelectorAll('.star').forEach(star => {
                star.addEventListener('click', function() {
                    selectedRating = parseInt(this.dataset.rating);
                    updateStars();
                });
                
                star.addEventListener('mouseover', function() {
                    const hoverRating = parseInt(this.dataset.rating);
                    highlightStars(hoverRating);
                });
            });

            document.querySelector('.rating-stars').addEventListener('mouseleave', function() {
                updateStars();
            });

            function updateStars() {
                highlightStars(selectedRating);
            }

            function highlightStars(rating) {
                document.querySelectorAll('.star').forEach((star, index) => {
                    if (index < rating) {
                        star.classList.add('active');
                    } else {
                        star.classList.remove('active');
                    }
                });
            }

            async function submitFeedback() {
                if (!selectedRating) {
                    showError('Please select a rating before submitting feedback.');
                    return;
                }

                const comments = document.getElementById('feedback-text').value.trim();

                try {
                    const response = await fetch('/feedback', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            rating: selectedRating,
                            comments: comments,
                            analysis_id: currentAnalysisId
                        })
                    });

                    if (response.ok) {
                        showSuccess('Thank you for your feedback!');
                        // Disable feedback form
                        document.querySelector('.feedback-section').innerHTML = '<p style="color: #4CAF50; font-weight: 600;">‚úÖ Thank you for your feedback!</p>';
                    } else {
                        showError('Failed to submit feedback. Please try again.');
                    }
                } catch (error) {
                    console.error('Feedback submission error:', error);
                    showError('Failed to submit feedback. Please try again.');
                }
            }

            function formatAnalysisText(text) {
                if (!text) return '<p>No analysis available.</p>';
                
                return text
                    .replace(/## (.*)/g, '<h3 style="color: #4CAF50; margin: 1.5rem 0 1rem 0;">$1</h3>')
                    .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
                    .replace(/‚Ä¢ (.*)/g, '<li style="margin: 0.5rem 0;">$1</li>')
                    .replace(/(\n\n)/g, '<br><br>')
                    .replace(/\n/g, '<br>');
            }

            // UI helper functions
            function showLoading(show) {
                const loading = document.getElementById('loading');
                const analyzeBtn = document.getElementById('analyze-btn');
                
                if (show) {
                    loading.style.display = 'block';
                    analyzeBtn.disabled = true;
                    analyzeBtn.textContent = 'Analyzing...';
                } else {
                    loading.style.display = 'none';
                    analyzeBtn.disabled = false;
                    analyzeBtn.textContent = 'üöÄ Analyze My Resume';
                }
            }

            function showError(message) {
                const errorDiv = document.getElementById('error-message');
                errorDiv.textContent = message;
                errorDiv.style.display = 'block';
                setTimeout(() => errorDiv.style.display = 'none', 8000);
            }

            function showSuccess(message) {
                const successDiv = document.getElementById('success-message');
                successDiv.textContent = message;
                successDiv.style.display = 'block';
                setTimeout(() => successDiv.style.display = 'none', 3000);
            }

            function hideMessages() {
                document.getElementById('error-message').style.display = 'none';
                document.getElementById('success-message').style.display = 'none';
            }
        </script>
    </body>
    </html>
    """
    return html_content

@app.route('/analyze-text', methods=['POST'])
@limiter.limit("10 per minute")
def analyze_text():
    """Analyze resume from text input with caching and analytics"""
    start_time = time.time()
    ip_address = get_remote_address()
    user_agent = request.headers.get('User-Agent', '')
    
    try:
        data = request.get_json()
        
        if not data or 'resume_text' not in data:
            log_analytics(ip_address, user_agent, 'text', 0, False, 'No resume text provided')
            return jsonify({
                'success': False,
                'error': 'No resume text provided',
                'code': 'MISSING_TEXT'
            }), 400
        
        resume_text = data['resume_text']
        
        # Validate content
        is_valid, validation_message = validate_resume_content(resume_text)
        if not is_valid:
            log_analytics(ip_address, user_agent, 'text', 0, False, validation_message, len(resume_text))
            return jsonify({
                'success': False,
                'error': validation_message,
                'code': 'INVALID_CONTENT'
            }), 400
        
        # Check cache first
        content_hash = get_content_hash(resume_text)
        cached_result = get_cached_analysis(content_hash)
        
        if cached_result:
            processing_time = time.time() - start_time
            log_analytics(ip_address, user_agent, 'text_cached', processing_time, True, None, len(resume_text))
            cached_result['from_cache'] = True
            return jsonify(cached_result)
        
        # Check if analyzer is available
        if ResumeAnalyzer is None:
            log_analytics(ip_address, user_agent, 'text', 0, False, 'ResumeAnalyzer not available')
            return jsonify({
                'success': False,
                'error': 'Resume analyzer service temporarily unavailable',
                'code': 'SERVICE_UNAVAILABLE'
            }), 503
        
        # Initialize analyzer and run analysis
        analyzer = ResumeAnalyzer()
        result = analyzer.analyze_resume_from_text(resume_text)
        
        # Add analysis ID for feedback tracking
        result['analysis_id'] = content_hash[:16]
        
        # Cache successful results
        if result.get('success'):
            cache_analysis(content_hash, result)
        
        processing_time = time.time() - start_time
        log_analytics(ip_address, user_agent, 'text', processing_time, result.get('success', False), 
                     result.get('error'), len(resume_text))
        
        logger.info(f"Text analysis completed in {processing_time:.2f}s: {result.get('success', False)}")
        return jsonify(result)
        
    except Exception as e:
        processing_time = time.time() - start_time
        error_message = f"Analysis failed: {str(e)}"
        log_analytics(ip_address, user_agent, 'text', processing_time, False, error_message)
        logger.error(f"Text analysis error: {e}\n{traceback.format_exc()}")
        
        return jsonify({
            'success': False,
            'error': 'Analysis failed due to server error',
            'code': 'PROCESSING_ERROR'
        }), 500

@app.route('/analyze-pdf', methods=['POST'])
@limiter.limit("5 per minute")
def analyze_pdf():
    """Analyze resume from PDF file with enhanced validation and analytics"""
    start_time = time.time()
    ip_address = get_remote_address()
    user_agent = request.headers.get('User-Agent', '')
    
    try:
        # Check if file was uploaded
        if 'file' not in request.files:
            log_analytics(ip_address, user_agent, 'pdf', 0, False, 'No file uploaded')
            return jsonify({
                'success': False,
                'error': 'No file uploaded',
                'code': 'MISSING_FILE'
            }), 400
        
        file = request.files['file']
        
        if file.filename == '':
            log_analytics(ip_address, user_agent, 'pdf', 0, False, 'No file selected')
            return jsonify({
                'success': False,
                'error': 'No file selected',
                'code': 'EMPTY_FILENAME'
            }), 400
        
        # Validate file type
        if not file.filename.lower().endswith('.pdf'):
            log_analytics(ip_address, user_agent, 'pdf', 0, False, 'Invalid file type')
            return jsonify({
                'success': False,
                'error': 'Only PDF files are allowed',
                'code': 'INVALID_FILE_TYPE'
            }), 400
        
        # Check file size
        file.seek(0, 2)  # Seek to end
        file_size = file.tell()
        file.seek(0)  # Reset to beginning
        
        if file_size > app.config['MAX_CONTENT_LENGTH']:
            log_analytics(ip_address, user_agent, 'pdf', 0, False, 'File too large', 0, file_size)
            return jsonify({
                'success': False,
                'error': 'File too large. Maximum size is 16MB.',
                'code': 'FILE_TOO_LARGE'
            }), 413
        
        # Save uploaded file temporarily
        filename = secure_filename(file.filename)
        timestamp = str(int(time.time()))
        unique_filename = f"{timestamp}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        file.save(filepath)
        
        try:
            # Check if analyzer is available
            if ResumeAnalyzer is None:
                log_analytics(ip_address, user_agent, 'pdf', 0, False, 'ResumeAnalyzer not available', 0, file_size)
                return jsonify({
                    'success': False,
                    'error': 'Resume analyzer service temporarily unavailable',
                    'code': 'SERVICE_UNAVAILABLE'
                }), 503
            
            # Initialize analyzer and run analysis
            analyzer = ResumeAnalyzer()
            result = analyzer.analyze_resume_from_pdf(filepath)
            
            # Add analysis ID for feedback tracking
            if result.get('success'):
                resume_length = result.get('resume_text_length', 0)
                content_hash = get_content_hash(str(result.get('extracted_profile', {})))
                result['analysis_id'] = content_hash[:16]
                
                # Cache successful results
                cache_analysis(content_hash, result)
            else:
                resume_length = 0
            
            processing_time = time.time() - start_time
            log_analytics(ip_address, user_agent, 'pdf', processing_time, result.get('success', False), 
                         result.get('error'), resume_length, file_size)
            
            logger.info(f"PDF analysis completed in {processing_time:.2f}s: {result.get('success', False)}")
            return jsonify(result)
            
        finally:
            # Clean up temporary file
            try:
                os.remove(filepath)
            except Exception as cleanup_error:
                logger.warning(f"Failed to cleanup temp file {filepath}: {cleanup_error}")
        
    except Exception as e:
        processing_time = time.time() - start_time
        error_message = f"PDF analysis failed: {str(e)}"
        log_analytics(ip_address, user_agent, 'pdf', processing_time, False, error_message, 0, file_size if 'file_size' in locals() else 0)
        logger.error(f"PDF analysis error: {e}\n{traceback.format_exc()}")
        
        return jsonify({
            'success': False,
            'error': 'Analysis failed due to server error',
            'code': 'PROCESSING_ERROR'
        }), 500

@app.route('/analyze-resume', methods=['POST'])
@limiter.limit("5 per minute")
def analyze_resume():
    """Unified endpoint for resume analysis (handles both PDF and text)"""
    start_time = time.time()
    ip_address = get_remote_address()
    user_agent = request.headers.get('User-Agent', '')
    
    try:
        # Check if it's a file upload (PDF) or JSON data (text)
        if 'file' in request.files:
            # Handle PDF upload
            file = request.files['file']
            
            if file.filename == '':
                log_analytics(ip_address, user_agent, 'resume', 0, False, 'No file selected')
                return jsonify({
                    'success': False,
                    'error': 'No file selected',
                    'message': 'Please select a PDF file to upload'
                }), 400
            
            # Validate file type
            if not file.filename.lower().endswith('.pdf'):
                log_analytics(ip_address, user_agent, 'resume', 0, False, 'Invalid file type')
                return jsonify({
                    'success': False,
                    'error': 'Only PDF files are allowed',
                    'message': 'Please upload a PDF file'
                }), 400
            
            # Check file size
            file.seek(0, 2)  # Seek to end
            file_size = file.tell()
            file.seek(0)  # Reset to beginning
            
            if file_size > app.config['MAX_CONTENT_LENGTH']:
                log_analytics(ip_address, user_agent, 'resume', 0, False, 'File too large', 0, file_size)
                return jsonify({
                    'success': False,
                    'error': 'File too large. Maximum size is 16MB.',
                    'message': 'Please upload a smaller PDF file'
                }), 413
            
            # For now, return a mock analysis since ResumeAnalyzer is not available
            # TODO: Replace this with actual PDF processing when ResumeAnalyzer is implemented
            
            # Generate mock analysis data
            mock_result = generate_mock_analysis(file.filename)
            
            processing_time = time.time() - start_time
            log_analytics(ip_address, user_agent, 'resume_pdf', processing_time, True, None, 0, file_size)
            
            logger.info(f"Mock PDF analysis completed in {processing_time:.2f}s")
            return jsonify(mock_result)
            
        else:
            # Handle text input (if implemented later)
            return jsonify({
                'success': False,
                'error': 'Text analysis not yet implemented',
                'message': 'Please upload a PDF file for analysis'
            }), 400
            
    except Exception as e:
        processing_time = time.time() - start_time
        error_message = f"Resume analysis failed: {str(e)}"
        log_analytics(ip_address, user_agent, 'resume', processing_time, False, error_message)
        logger.error(f"Resume analysis error: {e}\n{traceback.format_exc()}")
        
        return jsonify({
            'success': False,
            'error': 'Analysis failed due to server error',
            'message': 'Please try again later'
        }), 500

def generate_mock_analysis(filename):
    """Generate mock analysis data for demonstration"""
    import random
    
    # Simulate category detection based on filename
    categories = ['INFORMATION-TECHNOLOGY', 'HEALTHCARE', 'FINANCE', 'ENGINEERING', 'SALES', 'HR']
    detected_category = random.choice(categories)
    
    category_profiles = {
        'INFORMATION-TECHNOLOGY': {
            'roles': ['Software Developer', 'IT Manager', 'Systems Architect'],
            'skills': ['Programming', 'System Administration', 'Database Management', 'Cloud Computing', 'Cybersecurity'],
            'industry': 'Information Technology',
            'salary_range': '$85,000-$125,000'
        },
        'HEALTHCARE': {
            'roles': ['Healthcare Administrator', 'Clinical Manager', 'Medical Director'],
            'skills': ['Healthcare Management', 'Clinical Operations', 'Regulatory Compliance', 'Quality Improvement', 'Patient Care'],
            'industry': 'Healthcare',
            'salary_range': '$75,000-$110,000'
        },
        'FINANCE': {
            'roles': ['Financial Analyst', 'Investment Manager', 'CFO'],
            'skills': ['Financial Modeling', 'Investment Analysis', 'Risk Management', 'Financial Planning', 'Regulatory Compliance'],
            'industry': 'Finance',
            'salary_range': '$80,000-$120,000'
        },
        'ENGINEERING': {
            'roles': ['Software Engineer', 'Mechanical Engineer', 'Engineering Manager'],
            'skills': ['Engineering Design', 'Problem Solving', 'Technical Analysis', 'Project Management', 'Innovation'],
            'industry': 'Engineering',
            'salary_range': '$85,000-$120,000'
        },
        'SALES': {
            'roles': ['Sales Manager', 'Account Executive', 'Sales Director'],
            'skills': ['Sales Strategy', 'Lead Generation', 'Client Relations', 'Negotiation', 'CRM Management'],
            'industry': 'Sales',
            'salary_range': '$65,000-$95,000'
        },
        'HR': {
            'roles': ['HR Manager', 'Talent Acquisition Manager', 'HRBP'],
            'skills': ['Human Resources', 'Talent Management', 'Employee Relations', 'Recruitment', 'Organizational Development'],
            'industry': 'Human Resources',
            'salary_range': '$65,000-$90,000'
        }
    }
    
    profile_data = category_profiles[detected_category]
    experience_levels = ['entry', 'mid', 'senior', 'executive']
    locations = ['New York, NY', 'Los Angeles, CA', 'Chicago, IL', 'Houston, TX', 'Phoenix, AZ', 'Remote-friendly']
    
    exp_level = random.choice(experience_levels)
    years = random.randint(1, 2) if exp_level == 'entry' else random.randint(3, 15)
    
    return {
        'success': True,
        'message': 'Resume analysis completed successfully',
        'extracted_profile': {
            'experience_level': exp_level,
            'years_of_experience': years,
            'current_location': random.choice(locations),
            'job_categories': [detected_category.replace('-', ' ').title()],
            'target_roles': profile_data['roles'],
            'key_skills': profile_data['skills'],
            'industries': profile_data['industry'],
            'work_arrangement_preference': random.choice(['Remote', 'Hybrid', 'On-site', 'Flexible']),
            'estimated_salary_range': profile_data['salary_range'],
            'education_level': random.choice(["Bachelor's", "Master's", "PhD", "Professional"]),
            'career_focus': f"Professional growth and leadership in {profile_data['industry'].lower()}",
            'willing_to_relocate': random.choice([True, False]),
            'category': detected_category
        },
        'groq_analysis': {
            'analysis': f"""# Resume Analysis Report

## Market Competitiveness Assessment
Your profile shows strong potential in the {profile_data['industry']} sector with {years} years of experience. Current market readiness: {random.randint(7, 10)}/10.

## Target Role Fit Analysis
Excellent alignment with {profile_data['roles'][0]} and {profile_data['roles'][1]} positions. Your skill set directly matches industry requirements.

## Technical & Professional Skills Evaluation
Core competencies in {', '.join(profile_data['skills'][:3])} demonstrate strong foundation. Consider expanding into emerging technologies and methodologies.

## Experience & Achievement Analysis
Solid {exp_level}-level experience progression showing consistent growth in {profile_data['industry'].lower()} sector.

## Resume Optimization Recommendations
- Strengthen quantifiable achievements
- Add industry-specific keywords
- Highlight leadership experiences
- Include relevant certifications

## Career Development Roadmap
**Immediate (0-3 months):** Focus on skill enhancement and portfolio development
**Short-term (3-12 months):** Target {exp_level}-level positions with growth opportunities  
**Long-term (1-3 years):** Prepare for senior roles and specialized expertise

## Action Plan
- Apply to target roles immediately if market-ready
- Network with industry professionals
- Consider additional certifications
- Update LinkedIn and resume with optimized content
"""
        },
        'filename': filename,
        'analysis_type': 'comprehensive',
        'processing_time': random.uniform(2.0, 5.0)
    }

@app.route('/feedback', methods=['POST'])
@limiter.limit("20 per hour")
def submit_feedback():
    """Submit user feedback"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        rating = data.get('rating')
        comments = data.get('comments', '')
        analysis_id = data.get('analysis_id', '')
        
        # Validate rating
        if not rating or not isinstance(rating, int) or rating < 1 or rating > 5:
            return jsonify({
                'success': False,
                'error': 'Rating must be between 1 and 5'
            }), 400
        
        # Store feedback in database
        try:
            ip_address = get_remote_address()
            conn = sqlite3.connect('resume_analyzer.db')
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO feedback (ip_address, rating, comments, analysis_id)
                VALUES (?, ?, ?, ?)
            ''', (ip_address, rating, comments[:1000], analysis_id))  # Limit comments to 1000 chars
            conn.commit()
            conn.close()
            
            logger.info(f"Feedback received: {rating} stars from {ip_address}")
            
            return jsonify({
                'success': True,
                'message': 'Thank you for your feedback!'
            })
            
        except Exception as db_error:
            logger.error(f"Feedback storage error: {db_error}")
            return jsonify({
                'success': False,
                'error': 'Failed to store feedback'
            }), 500
        
    except Exception as e:
        logger.error(f"Feedback submission error: {e}")
        return jsonify({
            'success': False,
            'error': 'Failed to process feedback'
        }), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Comprehensive health check endpoint"""
    try:
        health_info = {
            'status': 'healthy',
            'timestamp': datetime.datetime.utcnow().isoformat(),
            'version': '1.0.0',
            'checks': {}
        }
        
        # Check Groq API key
        groq_key = os.getenv('GROQ_API_KEY')
        health_info['checks']['groq_api'] = {
            'status': 'configured' if groq_key else 'missing',
            'message': 'API key found' if groq_key else 'GROQ_API_KEY not configured'
        }
        
        # Check analyzer availability
        health_info['checks']['analyzer'] = {
            'status': 'available' if ResumeAnalyzer else 'unavailable',
            'message': 'ResumeAnalyzer loaded' if ResumeAnalyzer else 'ResumeAnalyzer not loaded'
        }
        
        # Check database connectivity
        try:
            conn = sqlite3.connect('resume_analyzer.db')
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM analytics')
            analytics_count = cursor.fetchone()[0]
            conn.close()
            
            health_info['checks']['database'] = {
                'status': 'healthy',
                'message': f'Database accessible, {analytics_count} analytics records'
            }
        except Exception as db_error:
            health_info['checks']['database'] = {
                'status': 'error',
                'message': f'Database error: {str(db_error)}'
            }
        
        # Check disk space for temp files
        try:
            import shutil
            total, used, free = shutil.disk_usage(app.config['UPLOAD_FOLDER'])
            free_gb = free // (1024**3)
            
            health_info['checks']['disk_space'] = {
                'status': 'healthy' if free_gb > 1 else 'warning',
                'message': f'{free_gb}GB free space available',
                'free_bytes': free
            }
        except Exception:
            health_info['checks']['disk_space'] = {
                'status': 'unknown',
                'message': 'Could not check disk space'
            }
        
        # Overall status
        failed_checks = [check for check in health_info['checks'].values() 
                        if check['status'] in ['error', 'unavailable']]
        
        if failed_checks:
            health_info['status'] = 'degraded'
            return jsonify(health_info), 503
        
        warning_checks = [check for check in health_info['checks'].values() 
                         if check['status'] == 'warning']
        
        if warning_checks:
            health_info['status'] = 'warning'
        
        return jsonify(health_info)
        
    except Exception as e:
        logger.error(f"Health check error: {e}")
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.datetime.utcnow().isoformat()
        }), 500

@app.route('/api/stats', methods=['GET'])
@limiter.limit("30 per hour")
def get_stats():
    """Get usage statistics (admin endpoint)"""
    try:
        conn = sqlite3.connect('resume_analyzer.db')
        cursor = conn.cursor()
        
        # Get basic stats
        cursor.execute('SELECT COUNT(*) FROM analytics WHERE success = 1')
        successful_analyses = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM analytics WHERE success = 0')
        failed_analyses = cursor.fetchone()[0]
        
        cursor.execute('SELECT AVG(rating) FROM feedback WHERE rating IS NOT NULL')
        avg_rating = cursor.fetchone()[0] or 0
        
        cursor.execute('SELECT COUNT(*) FROM feedback')
        total_feedback = cursor.fetchone()[0]
        
        # Get recent activity (last 24 hours)
        cursor.execute('''
            SELECT COUNT(*) FROM analytics 
            WHERE datetime(timestamp) > datetime('now', '-24 hours')
        ''')
        recent_activity = cursor.fetchone()[0]
        
        # Get analysis type breakdown
        cursor.execute('''
            SELECT analysis_type, COUNT(*) 
            FROM analytics 
            GROUP BY analysis_type
        ''')
        analysis_types = dict(cursor.fetchall())
        
        # Get average processing time
        cursor.execute('''
            SELECT AVG(processing_time) 
            FROM analytics 
            WHERE success = 1 AND processing_time > 0
        ''')
        avg_processing_time = cursor.fetchone()[0] or 0
        
        conn.close()
        
        stats = {
            'total_analyses': successful_analyses + failed_analyses,
            'successful_analyses': successful_analyses,
            'failed_analyses': failed_analyses,
            'success_rate': round((successful_analyses / (successful_analyses + failed_analyses)) * 100, 2) if (successful_analyses + failed_analyses) > 0 else 0,
            'average_rating': round(avg_rating, 2) if avg_rating else 0,
            'total_feedback': total_feedback,
            'recent_activity_24h': recent_activity,
            'analysis_types': analysis_types,
            'average_processing_time': round(avg_processing_time, 2),
            'generated_at': datetime.datetime.utcnow().isoformat()
        }
        
        return jsonify(stats)
        
    except Exception as e:
        logger.error(f"Stats endpoint error: {e}")
        return jsonify({
            'error': 'Failed to retrieve statistics'
        }), 500

@app.route('/api/info', methods=['GET'])
def api_info():
    """Get API information and documentation"""
    return jsonify({
        'name': 'Resume Analyzer API',
        'version': '1.0.0',
        'description': 'AI-powered resume analysis with job recommendations',
        'endpoints': {
            'GET /': 'Main web interface',
            'POST /analyze-text': 'Analyze resume from text input',
            'POST /analyze-pdf': 'Analyze resume from PDF file',
            'POST /feedback': 'Submit user feedback',
            'GET /health': 'Health check endpoint',
            'GET /api/stats': 'Usage statistics',
            'GET /api/info': 'API information'
        },
        'features': [
            'AI-powered job recommendations',
            'Content-based profile extraction',
            'Market salary insights',
            'ATS optimization suggestions',
            'Career development roadmap'
        ],
        'supported_formats': ['PDF', 'Plain Text'],
        'rate_limits': {
            'text_analysis': '10 per minute',
            'pdf_analysis': '5 per minute',
            'feedback': '20 per hour',
            'stats': '30 per hour'
        },
        'max_file_size': '16MB',
        'cache_duration': '24 hours',
        'documentation': 'https://github.com/your-repo/resume-analyzer'
    })

@app.route('/sitemap.xml', methods=['GET'])
def sitemap():
    """Generate sitemap for SEO"""
    from flask import make_response
    
    sitemap_xml = '''<?xml version="1.0" encoding="UTF-8"?>
    <urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
        <url>
            <loc>{base_url}</loc>
            <lastmod>{date}</lastmod>
            <changefreq>weekly</changefreq>
            <priority>1.0</priority>
        </url>
        <url>
            <loc>{base_url}/api/info</loc>
            <lastmod>{date}</lastmod>
            <changefreq>monthly</changefreq>
            <priority>0.5</priority>
        </url>
    </urlset>'''.format(
        base_url=request.url_root.rstrip('/'),
        date=datetime.datetime.utcnow().strftime('%Y-%m-%d')
    )
    
    response = make_response(sitemap_xml)
    response.headers['Content-Type'] = 'application/xml'
    return response

# Cleanup old cache entries (run periodically)
def cleanup_old_cache():
    """Remove cache entries older than 7 days"""
    try:
        conn = sqlite3.connect('resume_analyzer.db')
        cursor = conn.cursor()
        cursor.execute('''
            DELETE FROM analysis_cache 
            WHERE datetime(created_at) < datetime('now', '-7 days')
        ''')
        deleted = cursor.rowcount
        conn.commit()
        conn.close()
        
        if deleted > 0:
            logger.info(f"Cleaned up {deleted} old cache entries")
            
    except Exception as e:
        logger.error(f"Cache cleanup error: {e}")

# Background tasks (you might want to use Celery for production)
# Note: before_first_request was removed in Flask 3.0
# Startup tasks will be called manually in __main__
def startup_tasks():
    """Run startup tasks"""
    logger.info("Resume Analyzer API starting up...")
    cleanup_old_cache()

if __name__ == '__main__':
    # Environment validation
    required_env = []
    missing_env = []
    
    # Check for required environment variables
    groq_key = os.getenv('GROQ_API_KEY')
    if not groq_key:
        missing_env.append('GROQ_API_KEY')
    
    if missing_env:
        print("‚ö†Ô∏è  WARNING: Missing environment variables:")
        for env_var in missing_env:
            print(f"   - {env_var}")
        print("   The application may not work properly without them.")
        print("   Create a .env file with the required variables.")
        
        proceed = input("\nContinue anyway? (y/n): ").strip().lower()
        if proceed != 'y':
            print("Please set up your environment variables first.")
            exit(1)
    
    print("\nüöÄ PRODUCTION-READY RESUME ANALYZER API")
    print("=" * 50)
    print(f"üìç Local URL: http://127.0.0.1:5000")
    print(f"üìç Network URL: http://0.0.0.0:5000")
    print("\nüîß Available Endpoints:")
    print("   GET  /           - Web interface")
    print("   POST /analyze-text - Text analysis (10/min)")
    print("   POST /analyze-pdf  - PDF analysis (5/min)")
    print("   POST /feedback   - User feedback (20/hour)")
    print("   GET  /health     - Health check")
    print("   GET  /api/stats  - Usage statistics")
    print("   GET  /api/info   - API documentation")
    print("\n‚ú® Production Features:")
    print("   üõ°Ô∏è  Rate limiting & security")
    print("   üìä Analytics & monitoring") 
    print("   üíæ Intelligent caching")
    print("   üìù User feedback system")
    print("   üîç Health checks")
    print("   üìà Usage statistics")
    print("\nüí° Press Ctrl+C to stop the server")
    print("=" * 50)
    
    # Run startup tasks
    startup_tasks()
    
    # Run the Flask application
    app.run(
        host='0.0.0.0',           # Allow external connections
        port=int(os.getenv('PORT', 5000)),  # Use PORT env var for deployment
        debug=app.config['DEBUG'], # Use config debug setting
        threaded=True,            # Handle multiple requests
        use_reloader=False        # Disable reloader in production
    )